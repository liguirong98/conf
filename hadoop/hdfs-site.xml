<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
    <property>
        <name>hadoop.meta.dir</name>
        <value>/home/hadoop/dfs</value>
    </property>

    <!-- HA configuration -->
    <property>
        <name>dfs.nameservices</name>
        <value>vm</value>
    </property>
    <property>
        <name>dfs.ha.namenodes.vm</name>
        <value>nn1,nn2</value>
    </property>
     <property>
        <name>dfs.namenode.shared.edits.dir</name>
        <value>qjournal://vm1:8485;vm2:8485;vm3:8485/vm</value>
    </property>
    <property>
        <name>dfs.journalnode.edits.dir</name>
        <value>/home/hadoop/data/journal</value>
    </property>

    <property>
        <name>dfs.ha.automatic-failover.enabled.vm</name>
        <value>true</value>
    </property>
    <property>
        <name>dfs.client.failover.proxy.provider.vm</name>
        <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
    </property>
    <property>
        <name>dfs.ha.fencing.methods</name>
        <value>sshfence</value>
    </property>
    <property>
        <name>dfs.ha.fencing.ssh.private-key-files</name>
        <value>/home/hadoop/.ssh/id_rsa</value>
    </property>
    <property>
	<name>ha.zookeeper.quorum</name>
	<value>vm1:2181,vm2:2181,vm3:2181</value>
    </property>
    <property>
        <name>dfs.journalnode.http-address</name>
        <value>0.0.0.0:8480</value>
    </property>
    <property>
        <name>dfs.journalnode.rpc-address</name>
        <value>0.0.0.0:8485</value>
    </property>


    <!-- nn1 config -->
    <property>
        <name>dfs.namenode.servicerpc-address.vm.nn1</name>
        <value>vm1:19000</value>
    </property>
    <property>
        <name>dfs.namenode.rpc-address.vm.nn1</name>
        <value>vm1:9000</value>
    </property>
    <property>
        <name>dfs.namenode.http-address.vm.nn1</name>
        <value>vm1:50070</value>
    </property>

    <!-- nn2 config -->
    <property>
        <name>dfs.namenode.servicerpc-address.vm.nn2</name>
        <value>vm2:19000</value>
    </property>
    <property>
        <name>dfs.namenode.rpc-address.vm.nn2</name>
        <value>vm2:9000</value>
    </property>
    <property>
        <name>dfs.namenode.http-address.vm.nn2</name>
        <value>vm2:50070</value>
    </property>


    <property>
        <name>dfs.namenode.support.allow.format</name>
        <value>true</value>
    </property>
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>file://${hadoop.meta.dir}/name</value>
    </property>
    <property>
        <name>dfs.namenode.handler.count</name>
        <value>10</value>
    </property>
    <property>
        <name>dfs.replication</name>
        <value>1</value>
    </property>
    <property>
        <name>dfs.permissions.enabled</name>
        <value>true</value>
    </property>
    <property>
        <name>dfs.blocksize</name>
        <value>67108864</value>
    </property>
    <property>
        <name>dfs.namenode.avoid.write.stale.datanode</name>
        <value>true</value>
    </property>
    <property>
        <name>dfs.hosts</name>
        <value>${hadoop.meta.dir}/etc/hadoop/slaves</value>
    </property>
    <property>
        <name>dfs.hosts.exclude</name>
        <value>${hadoop.meta.dir}/etc/hadoop/exclude</value>
    </property>

    <property>
        <name>dfs.datanode.du.reserved</name>
        <value>1048576</value>
    </property>
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>${hadoop.meta.dir}/data/disk1,${hadoop.meta.dir}/data/disk2</value>
    </property>
    <property>
        <name>dfs.datanode.balance.bandwidthPerSec</name>
        <value>1048576</value>
    </property>
    <property>
        <name>dfs.client.block.write.replace-datanode-on-failure.enable</name>
        <value>false</value>
    </property>
    <!--
    <property>
        <name>dfs.heartbeat.interval</name>
        <value>30000</value>
    </property>
    -->
    <property>
        <name>dfs.stream-buffer-size</name>
        <value>4096</value>
    </property>
    <property>
        <name>dfs.datanode.handler.count</name>
        <value>10</value>
    </property>
    <property>
        <name>dfs.datanode.failed.volumes.tolerated</name>
        <value>1</value>
    </property>
</configuration>
